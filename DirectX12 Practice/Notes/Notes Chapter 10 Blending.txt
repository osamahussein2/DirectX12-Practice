We examine blending techniques which allow us to blend (combine) the pixels that we are currently rasterizing (so-called
source pixels) with the pixels that were previously rasterized to the back buffer (so-called destination pixels). This
technique enables us, among other things, to render semi-transparent objects such as water and glass.

Let Csrc be the color output from the pixel shader for the ijth pixel we are currently rasterizing (source pixel), and let Cdst
be the color of the ijth pixel currently on the back buffer (destination pixel).

Without blending, Csrc would overwrite Cdst (assuming it passes the depth/stencil test) and become the new color of the ijth
back buffer pixel. But with blending, Csrc and Cdst are blended together to get the new color C that will overwrite Cdst
(i.e., the blended color C will be written to the ijth pixel of the back buffer).

Direct3D uses the following blending equation to blend the source and destination pixel colors:
C = (Csrc * Fsrc) binary operator (Cdst * Fdst), this blending equation holds only for the RGB components of the colors.

The colors Fsrc (source blend factor) and Fdst (destination blend factor) allow us to modify the original source and
destination pixels in a variety of ways, allowing for different effects to be achieved.

The (X) or * operator means component wise multiplication for color vectors.

The alpha component is actually handled by a separate similar equation:
A = (Asrc * Fsrc) binary operator (Adst * Fdst)

The motivation for separating RGB from alpha is simply so that we can process them independently, and hence, differently, which
allows for a greater variety of possibilities.

Blending the alpha component is needed much less frequently than blending the RGB components. This is mainly because we do not
care about the back buffer alpha values. Back buffer alpha values are only important if you have some algorithm that requires
destination alpha values.

The binary operator used in the blending equation may be one of the following:

typedef enum D3D12_BLEND_OP
{
	D3D12_BLEND_OP_ADD = 1, C = Csrc * Fsrc + Cdst * Fdst
	D3D12_BLEND_OP_SUBTRACT = 2, C = Cdst * Fdst - Csrc * Fsrc
	D3D12_BLEND_OP_REV_SUBTRACT = 3, C = Csrc * Fsrc - Cdst * Fdst
	D3D12_BLEND_OP_MIN = 4, C = min(Csrc Cdst)
	D3D12_BLEND_OP_MAX = 5, C = max(Csrc Cdst)
} D3D12_BLEND_OP;

The blend factors are ignored in the min/max operation.

These same operators also work for the alpha blending equation. Also, you can specify a different operator for RGB and alpha.

A feature recently added to Direct3D is the ability to blend the source color and destination color using a logic operator
instead of the traditional blending equations above.

Note that you cannot use traditional blending and logic operator blending at the same time; you pick one or the other. Note
also that in order to use logic operator blending the render target format must support—it should be a format of the UINT
variety.

Letting Csrc = (rs, gs, bs), Asrc = as (the RGBA values output from the pixel shader), Cdst = (rd, gd, bd), Adst = ad (the
RGBA values already stored in the render target), F being either Fsrc or Fdst and F being either Fsrc or Fdst, we have:

D3D12_BLEND_ZERO: F = (0, 0, 0) and F = 0
D3D12_BLEND_ONE: F = (1, 1, 1) and F = 1
D3D12_BLEND_SRC_COLOR: F = (rs, gs, bs)
D3D12_BLEND_INV_SRC_COLOR: Fsrc = (1 - rs, 1 - gs, 1 - bs)
D3D12_BLEND_SRC_ALPHA: F = (as, as, as) and F = as
D3D12_BLEND_INV_SRC_ALPHA: F = (1 - as, 1 - as, 1 - as) and F = (1 - as)
D3D12_BLEND_DEST_ALPHA: F = (ad, ad, ad) and F = ad
D3D12_BLEND_INV_DEST_ALPHA: F = (1 - ad, 1 - ad, 1 - ad) and F = (1 - ad)
D3D12_BLEND_DEST_COLOR: F = (rd, gd, bd)
D3D12_BLEND_INV_DEST_COLOR: F = (1 - rd, 1 - gd, 1 - bd)
D3D12_BLEND_SRC_ALPHA_SAT: F = (a's, a's, a's) and F = a's where a's = clamp(as, 0, 1)

D3D12_BLEND_BLEND_FACTOR: F = (r, g, b) and F = a, where the color (r, g, b, a) is supplied to the second parameter of the
ID3D12GraphicsCommandList::OMSetBlendFactor method. This allows you to specify the blend factor color to use directly; however,
it is constant until you change the blend state.

D3D12_BLEND_INV_BLEND_FACTOR: F = (1 - r, 1 - g, 1 - b) and F = 1 - a, where the color (r, g, b, a) is supplied by the second
parameter of the ID3D12GraphicsCommandList::OMSetBlendFactor method. This allows you to specify the blend factor color to use
directly; however, it is constant until you change the blend state.

We can set the blend factor color with the following function: 
void ID3D12GraphicsCommandList::OMSetBlendFactor(const FLOAT BlendFactor[ 4 ]);

- Passing a nullptr restores the default blend factor of (1, 1, 1, 1)

To configure a non-default blend state we must fill out a D3D12_BLEND_DESC structure. The D3D12_BLEND_DESC structure is defined
like so:

typedef struct D3D12_BLEND_DESC {
	BOOL AlphaToCoverageEnable; // Default: False
	BOOL IndependentBlendEnable; // Default: False
	D3D11_RENDER_TARGET_BLEND_DESC RenderTarget[8];
} D3D11_BLEND_DESC;

Blending is not free and does require additional per-pixel work, so only enable it if you need it, and turn it off when you
are done.

Suppose that we want to keep the original destination pixel exactly as it is and not overwrite it or blend it with the source
pixel currently being rasterized. This can be useful, for example, if you just want to write to the depth/stencil buffer, and
not the back buffer. To do this, set the source pixel blend factor to D3D12_BLEND_ZERO, the destination blend factor to
D3D12_BLEND_ONE, and the blend operator to D3D12_BLEND_OP_ADD. With this setup, the blending equation reduces to:

C = (Csrc * Fsrc) binary operator (Cdst * Fdst)
C = (Csrc * (0, 0, 0)) + (Cdst * (1, 1, 1))
C = Cdst

This is a contrived example; another way to implement the same thing would be to set the
D3D12_RENDER_TARGET_BLEND_DESC::RenderTargetWriteMask member to 0, so that none of the color channels are written to.

Adding source and destination color. Adding creates a brighter image since color is being added.

Subtracting source color from destination color. Subtraction creates a darker image since color is being removed.

Suppose that we want to add the source pixels with the destination pixels. To do this, set the source blend factor to
D3D12_BLEND_ONE, the destination blend factor to D3D12_BLEND_ONE, and the blend operator to D3D12_BLEND_OP_ADD.

We can subtract source pixels from destination pixels by using the above blend factors and replacing the blend operation with
D3D12_BLEND_OP_SUBTRACT.

Suppose that we want to multiply a source pixel with its corresponding destination pixel. To do this, we set the source blend
factor to D3D12_BLEND_ZERO, the destination blend factor to D3D12_BLEND_SRC_COLOR, and the blend operator to D3D12_BLEND_OP_ADD.
With this setup, the blending equation reduces to:

C = (Csrc * Fsrc) binary operator (Cdst * Fdst)
C = (Csrc * (0, 0, 0)) + (Cdst * Csrc)
C = (Cdst * Csrc)

Let the source alpha component as be thought of as a percent that controls the opacity of the source pixel (e.g., 0 alpha
means 0% opaque, 0.4 means 40% opaque, and 1.0 means 100% opaque).

The relationship between opacity and transparency is simply T = 1 - A, where A is opacity and T is transparency. For instance,
if something is 0.4 opaque, then it is 1 - 0.4 = 0.6 transparent.

Now suppose that we want to blend the source and destination pixels based on the opacity of the source pixel. To do this, set
the source blend factor to D3D12_BLEND_SRC_ALPHA and the destination blend factor to D3D12_BLEND_INV_SRC_ALPHA, and the blend
operator to D3D12_BLEND_OP_ADD. With this setup, the blending equation reduces to:

C = (Csrc * Fsrc) binary operator (Cdst * Fdst)
C = (Csrc * (as, as, as)) + (Cdst * (1 - as, 1 - as, 1 - as))
C = as * Csrc + (1 - as) * Cdst

For example, suppose as = 0.25, which is to say the source pixel is only 25% opaque. Then when the source and destination
pixels are blended together, we expect the final color will be a combination of 25% of the source pixel and 75% of the
destination pixel (the pixel "behind" the source pixel), since the source pixel is 75% transparent. The equation above gives
us precisely this:

C = as * Csrc + (1 - as) * Cdst
C = 0.25 * Csrc + 0.75 * Cdst

Using this blending method, we can draw transparent objects.

It should be noted that with this blending method, the order that you draw the objects matters. We use the following rule:

1. Draw objects that do not use blending first.
2. Sort the objects that use blending by their distance from the camera.
3. Draw the objects that use blending in a back-to-front order.

The reason for the back-to-front draw order is so that objects are blended with the objects spatially behind them. For if an
object is transparent, we can see through it to see the scene behind it. So it is necessary that all the pixels behind the
transparent object have already been written to the back buffer, so that we can blend the transparent source pixels with the
destination pixels of the scene behind it.

If we are rendering a set S of objects with additive blending, the idea is that the objects in S do not obscure each other;
instead, their colors are meant to simply accumulate. Therefore, we do not want to perform the depth test between objects in S;
for if we did, without a back-to-front draw ordering, one of the objects in S would obscure another object in S, thus causing
the pixel fragments to be rejected due to the depth test, which means that object’s pixel colors would not be accumulated into
the blend sum.

We can disable the depth test between objects in S by disabling writes to the depth buffer while rendering objects in S.
Because depth writes are disabled, the depths of an object in S drawn with additive blending will not be written to the depth
buffer; hence, this object will not obscure any later drawn object in S behind it due to the depth test. Note that we only
disable depth writes while drawing the objects in S (the set of objects drawn with additive blending).

Depth reads and the depth test are still enabled. This is so that non-blended geometry (which is drawn before blended geometry)
will still obscure blended geometry behind it. For example, if you have a set of additively blended objects behind a wall, you
will not see the blended objects because the solid wall obscures them.

Sometimes we want to completely reject a source pixel from being further processed. This can be done with the intrinsic HLSL
clip(x) function. This function can only be called in a pixel shader, and it discards the current pixel from further processing
if x < 0. That is, it is useful for rendering pixels where a pixel is either completely opaque or completely transparent.

In the pixel shader, we grab the alpha component of the texture. If it is a small value close to 0, which indicates that the
pixel is completely transparent, then we clip the pixel from further processing.

By discarding a pixel early from the pixel shader, the remaining pixel shader instructions can be skipped (no point in doing
the calculations for a discarded pixel).

To simulate certain types of weather conditions in our games, we need to be able to implement a fog effect. In addition to the
obvious purposes of fog, fog provides some fringe benefits. For example, it can mask distant rendering artifacts and prevent
popping. Popping refers to when an object that was previously behind the far plane all of a sudden comes in front of the
frustum, due to camera movement, and thus becomes visible; so it seems to "pop" into the scene abruptly. By having a layer of
fog in the distance, the popping is hidden.

Note that if your scene takes place on a clear day, you may wish to still include a subtle amount of fog at far distances,
because, even on clear days, distant objects such as mountains appear hazier and lose contrast as a function of depth, and we
can use fog to simulate this atmospheric perspective phenomenon.

Our strategy for implementing fog works as follows: We specify a fog color, a fog start distance from the camera and a fog
range (i.e., the range from the fog start distance until the fog completely hides any objects). Then the color of a point
on a triangle is a weighted average of its usual color and the fog color:

foggedColor = litColor + (s fogColor-litColor)
= (1 - s) * litColor + s * fogColor

The parameter s ranges from 0 to 1 and is a function of the distance between the camera position and the surface point. As the
distance between a surface point and the eye increases, the point becomes more and more obscured by the fog. The parameter s is
defined as follows:

s = saturate(dist(p, E) - fogStart / fogRange) where dist (p, E) is the distance between the surface point p and the camera
position E. The saturate function clamps the argument to the range [0, 1].

In other words, the fog does not modify the color of vertices whose distance from the camera is less than fogStart. This makes
sense based on the name "fogStart"; the fog does not start affecting the color until the distance from the camera is at least
that of fogStart.

Let fogEnd = fogStart + fogRange. When dist(p, E) > fogEnd, s = 1 and the fogged color is given by: foggedColor = fogColor

In other words, the fog completely hides the surface point at distances greater than or equal to fogEnd - so all you see is the
fog color.

When fogStart < dist(p, E) < fogEnd, we see that s linearly ramps up from 0 to 1 as dist(p, E) increases from fogStart to
fogEnd. This means that as the distance increases, the fog color gets more and more weight while the original color gets less
and less weight. This makes sense, of course, because as the distance increases, the fog obscures more and more of the surface
point.

For the alpha blending equation, blend factors ending with _COLOR are not allowed.